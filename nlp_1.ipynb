{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOIr2+XKB3aV7c8N2KFHpkH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6NG8P7YUwJ7J","executionInfo":{"status":"ok","timestamp":1768280958588,"user_tz":-330,"elapsed":4414,"user":{"displayName":"Code_Crusaders","userId":"01357471722438984246"}},"outputId":"034b4e4b-9478-4024-bcc9-c43cb980ef69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"]}],"source":["!pip install nltk"]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, TreebankWordTokenizer, TweetTokenizer, MWETokenizer\n","from nltk.stem import PorterStemmer, SnowballStemmer\n","from nltk.stem import WordNetLemmatizer"],"metadata":{"id":"h10RV652wnG_","executionInfo":{"status":"ok","timestamp":1768281021361,"user_tz":-330,"elapsed":2220,"user":{"displayName":"Code_Crusaders","userId":"01357471722438984246"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pCalFbAwzV_","executionInfo":{"status":"ok","timestamp":1768281049678,"user_tz":-330,"elapsed":816,"user":{"displayName":"Code_Crusaders","userId":"01357471722438984246"}},"outputId":"e010a3d9-a2aa-49c4-a37f-1730a1134900"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["text = \"This is Assignment no one of NLP subject .Don't hesitate to ask questions! NLP is fun i am a student of Cse AI stdying NLP\"\n","print(\"Original Text:\\n\", text)\n","print(\"=\"*60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_C6ulwBJw5l9","executionInfo":{"status":"ok","timestamp":1768281149160,"user_tz":-330,"elapsed":8,"user":{"displayName":"Code_Crusaders","userId":"01357471722438984246"}},"outputId":"064da157-2a1b-4d77-bd21-f59e24c81fd9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text:\n"," This is Assignment no one of NLP subject .Don't hesitate to ask questions! NLP is fun i am a student of Cse AI stdying NLP\n","============================================================\n"]}]},{"cell_type":"code","source":["# Whitespace Tokenizer\n","whitespace_tokens = WhitespaceTokenizer().tokenize(text)\n","print(\"Whitespace Tokenizer:\", whitespace_tokens)\n","# Punctuation-based Tokenizer\n","punct_tokens = WordPunctTokenizer().tokenize(text)\n","print(\"Punctuation Tokenizer:\", punct_tokens)\n","# Treebank Tokenizer\n","treebank_tokens = TreebankWordTokenizer().tokenize(text)\n","print(\"Treebank Tokenizer:\", treebank_tokens)\n","# Tweet Tokenizer\n","tweet_tokens = TweetTokenizer().tokenize(text)\n","print(\"Tweet Tokenizer:\", tweet_tokens)\n","# MWE Tokenizer (Multi-Word Expressions)\n","mwe_tokenizer = MWETokenizer([(\"natural\", \"language\"), (\"New\", \"York\")])\n","mwe_tokens = mwe_tokenizer.tokenize(text.split())\n","print(\"MWE Tokenizer:\", mwe_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZGcgtQxxRj7","executionInfo":{"status":"ok","timestamp":1768281342099,"user_tz":-330,"elapsed":24,"user":{"displayName":"Code_Crusaders","userId":"01357471722438984246"}},"outputId":"20d427fd-dc6a-4458-896e-2b7941f8f10e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Whitespace Tokenizer: ['This', 'is', 'Assignment', 'no', 'one', 'of', 'NLP', 'subject', \".Don't\", 'hesitate', 'to', 'ask', 'questions!', 'NLP', 'is', 'fun', 'i', 'am', 'a', 'student', 'of', 'Cse', 'AI', 'stdying', 'NLP']\n","Punctuation Tokenizer: ['This', 'is', 'Assignment', 'no', 'one', 'of', 'NLP', 'subject', '.', 'Don', \"'\", 't', 'hesitate', 'to', 'ask', 'questions', '!', 'NLP', 'is', 'fun', 'i', 'am', 'a', 'student', 'of', 'Cse', 'AI', 'stdying', 'NLP']\n","Treebank Tokenizer: ['This', 'is', 'Assignment', 'no', 'one', 'of', 'NLP', 'subject', '.Do', \"n't\", 'hesitate', 'to', 'ask', 'questions', '!', 'NLP', 'is', 'fun', 'i', 'am', 'a', 'student', 'of', 'Cse', 'AI', 'stdying', 'NLP']\n","Tweet Tokenizer: ['This', 'is', 'Assignment', 'no', 'one', 'of', 'NLP', 'subject', '.', \"Don't\", 'hesitate', 'to', 'ask', 'questions', '!', 'NLP', 'is', 'fun', 'i', 'am', 'a', 'student', 'of', 'Cse', 'AI', 'stdying', 'NLP']\n","MWE Tokenizer: ['This', 'is', 'Assignment', 'no', 'one', 'of', 'NLP', 'subject', \".Don't\", 'hesitate', 'to', 'ask', 'questions!', 'NLP', 'is', 'fun', 'i', 'am', 'a', 'student', 'of', 'Cse', 'AI', 'stdying', 'NLP']\n"]}]},{"cell_type":"code","source":["print(\"\\n--- STEMMING ---\")\n","porter = PorterStemmer()\n","snowball = SnowballStemmer(\"english\")\n","porter_stems = [porter.stem(token) for token in treebank_tokens]\n","snowball_stems = [snowball.stem(token) for token in treebank_tokens]\n","print(\"Porter Stemmer:\", porter_stems)\n","print(\"Snowball Stemmer:\", snowball_stems)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AsSlMaMEz4Rx","executionInfo":{"status":"ok","timestamp":1768281869972,"user_tz":-330,"elapsed":24,"user":{"displayName":"Code_Crusaders","userId":"01357471722438984246"}},"outputId":"63efae99-ea44-4579-e068-ca7e3468e536"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- STEMMING ---\n","Porter Stemmer: ['thi', 'is', 'assign', 'no', 'one', 'of', 'nlp', 'subject', '.do', \"n't\", 'hesit', 'to', 'ask', 'question', '!', 'nlp', 'is', 'fun', 'i', 'am', 'a', 'student', 'of', 'cse', 'ai', 'stdi', 'nlp']\n","Snowball Stemmer: ['this', 'is', 'assign', 'no', 'one', 'of', 'nlp', 'subject', '.do', \"n't\", 'hesit', 'to', 'ask', 'question', '!', 'nlp', 'is', 'fun', 'i', 'am', 'a', 'student', 'of', 'cse', 'ai', 'stdi', 'nlp']\n"]}]},{"cell_type":"code","source":["print(\"\\n--- LEMMATIZATION ---\")\n","lemmatizer = WordNetLemmatizer()\n","lemmas = [lemmatizer.lemmatize(token) for token in treebank_tokens]\n","print(\"WordNet Lemmatizer:\", lemmas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qzkqu6hF0DKj","executionInfo":{"status":"ok","timestamp":1768281907221,"user_tz":-330,"elapsed":2463,"user":{"displayName":"Code_Crusaders","userId":"01357471722438984246"}},"outputId":"29035d6b-b4af-47a8-d8f2-a040aaa9bdd9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- LEMMATIZATION ---\n","WordNet Lemmatizer: ['This', 'is', 'Assignment', 'no', 'one', 'of', 'NLP', 'subject', '.Do', \"n't\", 'hesitate', 'to', 'ask', 'question', '!', 'NLP', 'is', 'fun', 'i', 'am', 'a', 'student', 'of', 'Cse', 'AI', 'stdying', 'NLP']\n"]}]}]}